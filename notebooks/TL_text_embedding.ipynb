{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning on A Pre-Trained Text Embedding Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"thenlper/gte-base\" # This model is fairly small and is #22 on MTEB leaderboard\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_text_model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTextEmbeddingModel(torch.nn.Module):\n",
    "    def __init__(self, original_model, output_dim):\n",
    "        super(CustomTextEmbeddingModel, self).__init__()\n",
    "        self.original_model = original_model\n",
    "        # 768 is the embedding dims for the original gte-base model. adding another layer on the end to project to the output dim\n",
    "        if output_dim == 768:\n",
    "            self.projection = torch.nn.Identity()\n",
    "            for param in self.projection.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            self.projection = torch.nn.Linear(768, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # Original model output\n",
    "        outputs = self.original_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = self._average_pool(outputs.last_hidden_state, attention_mask)\n",
    "        # Project to new output dim\n",
    "        projected_output = self.projection(pooled_output)\n",
    "        return projected_output\n",
    "    \n",
    "    # This function is from https://huggingface.co/thenlper/gte-base\n",
    "    def _average_pool(self, last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1915, -0.0581,  0.1463,  ...,  0.2232,  0.2082, -0.5509],\n",
      "        [ 0.0026, -0.1361,  0.1179,  ..., -0.0378,  0.2154, -0.3237]])\n",
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "# A test to verify that the text model is working\n",
    "text_model = CustomTextEmbeddingModel(base_text_model, 768)\n",
    "\n",
    "# Tokenize test inputs\n",
    "test_inputs = [\"This is test sentence 1\", \"This is test sentence 2\"]\n",
    "batch_dict = tokenizer(test_inputs, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Pass the tokenized inputs through your custom model\n",
    "with torch.no_grad():\n",
    "    embeddings = text_model(batch_dict['input_ids'], batch_dict['attention_mask'])\n",
    "\n",
    "#print(batch_dict)\n",
    "print(embeddings)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freeze Pre-Trained Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_pretrained_weights(model: nn.Module):\n",
    "    '''\n",
    "    Freezes the pretrained weights for an instance of the CustomTextEmbeddingModel class\n",
    "    '''\n",
    "    for param in model.original_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    # Turn the gradients back on for the final 2 linear layers\n",
    "    model.original_model.encoder.layer[10].output.requires_grad = True\n",
    "    #print(model.original_model.encoder.layer[11].output.dense)\n",
    "    model.original_model.encoder.layer[11].output.requires_grad = True\n",
    "    #print(model.original_model.pooler.dense)\n",
    "    model.original_model.pooler.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup a Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        encoded_text = self.tokenizer(self.texts[idx], return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return encoded_text, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text, labels, and tokenizer\n",
    "    # Image captions\n",
    "texts = [\"Caption for image 1\", \"Caption for image 2\", \"Caption for image 3\"]\n",
    "    # The labels are the image embeddings from the image embedding model.\n",
    "labels = [Tensor([1,2,3,4,5,6,7,8,9,0]), Tensor([1,2,3,4,5,6,7,8,9,0]), Tensor([1,2,3,4,5,6,7,8,9,0])]\n",
    "    # This is the tokenizer for our base pretrained text embedding model: gte-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "dataset = TextDataset(texts, labels, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Embeddings from Pre-Trained ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible models\n",
    "# oschamp/vit-artworkclassifier        probably not this one... its finetuning seems to be somewhat poor\n",
    "# google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: book jacket, dust cover, dust jacket, dust wrapper\n"
     ]
    }
   ],
   "source": [
    "# Load the google ViT model\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "image_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "test_image = Image.open(\"../data/test_art.jpg\")\n",
    "\n",
    "inputs = processor(images=test_image, return_tensors=\"pt\")\n",
    "outputs = image_model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", image_model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Extract the embeddings from the model by removing the final classification layer\n",
    "image_model.classifier = nn.Identity()\n",
    "\n",
    "embedding = image_model(**inputs).logits\n",
    "\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "# Example of how to create embedding labels for our image dataset\n",
    "image_model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "image_model.classifier = nn.Identity()\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "\n",
    "images = [test_image]\n",
    "inputs = processor(images=images, return_tensors=\"pt\")\n",
    "embeddings = image_model(**inputs).logits\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "old_man_caption = \"A older man with a white shirt, golf cap and a cane walks away from an outdoor flower shop.\"\n",
    "old_man_image = Image.open(\"../data/old_man.jpg\")\n",
    "# Resize the image to 224x224\n",
    "old_man_image = old_man_image.resize((224, 224))\n",
    "\n",
    "images = [old_man_image]\n",
    "inputs = processor(images=images, return_tensors=\"pt\")\n",
    "old_man_embeddings = image_model(**inputs).logits\n",
    "print(old_man_embeddings.shape)\n",
    "\n",
    "# Pass caption through text model\n",
    "text_model.load_state_dict(torch.load(\"C:/Users/nickj/Downloads/finetuned_text_model.pth\"))\n",
    "\n",
    "# Tokenize test inputs\n",
    "batch_dict = tokenizer(old_man_caption, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Pass the tokenized inputs through your custom model\n",
    "with torch.no_grad():\n",
    "    text_old_man_embedding = text_model(batch_dict['input_ids'], batch_dict['attention_mask'])\n",
    "\n",
    "print(text_old_man_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04225935786962509\n"
     ]
    }
   ],
   "source": [
    "# FWrite function to calc cosine similarity\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    '''\n",
    "    Calculate the cosine similarity between two embeddings\n",
    "    '''\n",
    "    return F.cosine_similarity(embedding1, embedding2, dim=1)\n",
    "\n",
    "# Calculate the cosine similarity between two embeddings\n",
    "similarity = cosine_similarity(old_man_embeddings, text_old_man_embedding)\n",
    "\n",
    "print(similarity.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune Final Layers in Text Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flickr30kDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataset = load_dataset(path=\"nlphuji/flickr30k\", cache_dir=\"./huggingface_data\")\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        self.cap_per_image = 2\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.num_rows[\"test\"] * self.cap_per_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original_idx = idx // self.cap_per_image\n",
    "        # image_path = self.dataset[idx][\"image_path\"]\n",
    "        image = self.dataset[\"test\"][original_idx][\"image\"].convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        caption = self.dataset[\"test\"][original_idx][\"caption\"][idx % self.cap_per_image]\n",
    "        return {\"image\": image, \"caption\": caption}\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "flickr30k_custom_dataset = Flickr30kDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training loop to finetune the final three layers of the text embedding model\n",
    "text_model = text_model.to(device)\n",
    "freeze_pretrained_weights(text_model)\n",
    "image_model = image_model.to(device)\n",
    "\n",
    "# Define the optimizer, loss, and data loader\n",
    "optimizer = torch.optim.Adam(text_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.CosineEmbeddingLoss()\n",
    "dataloader = DataLoader(flickr30k_custom_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "training_losses = []\n",
    "\n",
    "# Training loop\n",
    "c = 0\n",
    "for epoch in range(1):\n",
    "    for batch in dataloader:\n",
    "        # Get the image and caption from the batch\n",
    "        images = batch[\"image\"].to(device)\n",
    "        captions = batch[\"caption\"]\n",
    "\n",
    "        # Get the image embeddings\n",
    "        image_inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        image_embeddings = image_model(**image_inputs).logits\n",
    "\n",
    "        # Get the text embeddings\n",
    "        text_inputs = tokenizer(captions, return_tensors='pt', padding='max_length', truncation=True, max_length=512).to(device)\n",
    "        input_ids = text_inputs['input_ids'].to(device)\n",
    "        attention_mask = text_inputs['attention_mask'].to(device)\n",
    "        text_embeddings = text_model(input_ids, attention_mask)\n",
    "\n",
    "        # Calculate the loss\n",
    "        target = torch.ones(1).to(device)\n",
    "        loss = loss_fn(text_embeddings, image_embeddings, target)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_losses.append(loss.item())\n",
    "        \n",
    "        c += 1\n",
    "        if c%100 == 0:\n",
    "            print(f\"Batch {c}, Loss: {loss.item()}\")\n",
    "        if c == 600:\n",
    "            torch.save(text_model.state_dict(), \"finetuned_text_model.pth\")\n",
    "\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": <class '__main__.CustomTextEmbeddingModel'>\n",
      "original_model: <class 'transformers.models.bert.modeling_bert.BertModel'>\n",
      "original_model.embeddings: <class 'transformers.models.bert.modeling_bert.BertEmbeddings'>\n",
      "original_model.embeddings.word_embeddings: <class 'torch.nn.modules.sparse.Embedding'>\n",
      "original_model.embeddings.position_embeddings: <class 'torch.nn.modules.sparse.Embedding'>\n",
      "original_model.embeddings.token_type_embeddings: <class 'torch.nn.modules.sparse.Embedding'>\n",
      "original_model.embeddings.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.embeddings.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder: <class 'transformers.models.bert.modeling_bert.BertEncoder'>\n",
      "original_model.encoder.layer: <class 'torch.nn.modules.container.ModuleList'>\n",
      "original_model.encoder.layer.0: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.0.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.0.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.0.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.0.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.0.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.0.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.0.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.0.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.0.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.0.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.0.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.0.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.1: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.1.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.1.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.1.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.1.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.1.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.1.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.1.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.1.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.1.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.1.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.1.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.1.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.2: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.2.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.2.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.2.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.2.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.2.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.2.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.2.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.2.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.2.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.2.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.2.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.2.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.3: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.3.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.3.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.3.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.3.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.3.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.3.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.3.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.3.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.3.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.3.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.3.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.3.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.4: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.4.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.4.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.4.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.4.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.4.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.4.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.4.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.4.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.4.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.4.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.4.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.4.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.5: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.5.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.5.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.5.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.5.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.5.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.5.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.5.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.5.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.5.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.5.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.5.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.5.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.6: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.6.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.6.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.6.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.6.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.6.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.6.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.6.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.6.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.6.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.6.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.6.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.6.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.7: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.7.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.7.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.7.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.7.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.7.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.7.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.7.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.7.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.7.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.7.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.7.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.7.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.8: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.8.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.8.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.8.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.8.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.8.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.8.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.8.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.8.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.8.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.8.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.8.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.8.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.9: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.9.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.9.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.9.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.9.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.9.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.9.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.9.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.9.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.9.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.9.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.9.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.9.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.10: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.10.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.10.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.10.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.10.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.10.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.10.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.10.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.10.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.10.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.10.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.10.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.10.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.11: <class 'transformers.models.bert.modeling_bert.BertLayer'>\n",
      "original_model.encoder.layer.11.attention: <class 'transformers.models.bert.modeling_bert.BertAttention'>\n",
      "original_model.encoder.layer.11.attention.self: <class 'transformers.models.bert.modeling_bert.BertSelfAttention'>\n",
      "original_model.encoder.layer.11.attention.self.query: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.attention.self.key: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.attention.self.value: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.attention.self.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.11.attention.output: <class 'transformers.models.bert.modeling_bert.BertSelfOutput'>\n",
      "original_model.encoder.layer.11.attention.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.attention.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.11.attention.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.encoder.layer.11.intermediate: <class 'transformers.models.bert.modeling_bert.BertIntermediate'>\n",
      "original_model.encoder.layer.11.intermediate.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.intermediate.intermediate_act_fn: <class 'transformers.activations.GELUActivation'>\n",
      "original_model.encoder.layer.11.output: <class 'transformers.models.bert.modeling_bert.BertOutput'>\n",
      "original_model.encoder.layer.11.output.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.encoder.layer.11.output.LayerNorm: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
      "original_model.encoder.layer.11.output.dropout: <class 'torch.nn.modules.dropout.Dropout'>\n",
      "original_model.pooler: <class 'transformers.models.bert.modeling_bert.BertPooler'>\n",
      "original_model.pooler.dense: <class 'torch.nn.modules.linear.Linear'>\n",
      "original_model.pooler.activation: <class 'torch.nn.modules.activation.Tanh'>\n",
      "projection: <class 'torch.nn.modules.linear.Identity'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in text_model.named_modules():\n",
    "    print(f\"{name}: {type(module)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
